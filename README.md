# Ollama Kubernetes Stack

ğŸš€ **Enterprise-ready Kubernetes deployment for Ollama AI stack**

[![CI](https://github.com/your-org/ollama-kubernetes-stack/workflows/CI/badge.svg)](https://github.com/your-org/ollama-kubernetes-stack/actions)
[![Helm](https://img.shields.io/badge/Helm-v3.12+-blue.svg)](https://helm.sh)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-v1.28+-blue.svg)](https://kubernetes.io)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## âœ¨ Features

- ğŸ¤– **Ollama AI Server** - Local LLM inference (CodeLlama, Llama3.2:3b, Gemma2:4b)
- ğŸŒ **OpenWebUI** - Beautiful web interface for AI interactions
- ğŸ“Š **Grafana** - Real-time monitoring and metrics dashboard
- ğŸ”’ **Tailscale** - Secure remote access via mesh networking
- â˜¸ï¸ **Kubernetes** - Cloud-native orchestration and scaling
- ğŸ“¦ **Helm** - Professional package management
- ğŸ”„ **GitOps** - Infrastructure as Code with CI/CD

## ğŸš€ Quick Start

```bash
# One-click installation
./scripts/install.sh

# Access your AI stack
open http://192.168.1.101:8080  # OpenWebUI
open http://192.168.1.102:3000  # Grafana
```

## ğŸ—ï¸ Architecture

Your stack runs on:
- **Hardware**: AMD Ryzen AI 9 HX 370, 96GB
- **Storage**: 1TB NVMe SSD at `/mnt/evo4t`
- **Network**: LoadBalancer services + Tailscale mesh
- **Monitoring**: Prometheus + Grafana dashboards

```mermaid
graph TB
    subgraph "External Access"
        U[ğŸ‘¥ Users] 
        I[ğŸŒ Internet/LAN]
        T[ğŸ”’ Tailscale<br/>100.102.114.95]
    end
    
    subgraph "Kubernetes Cluster (MicroK8s)"
        subgraph "Load Balancer (MetalLB)"
            LB1[ğŸŒ OpenWebUI LB<br/>192.168.1.101:8080]
            LB2[ğŸ“Š Grafana LB<br/>192.168.1.102:3000]
        end
        
        subgraph "ollama-stack namespace"
            WP[ğŸ–¥ï¸ OpenWebUI Pod]
            OP[ğŸ§  Ollama Pod<br/>Models: CodeLlama, Llama3.2:3b, Gemma2:4b]
        end
        
        subgraph "observability namespace"
            GP[ğŸ“Š Grafana Pod]
            PP[ğŸ“ˆ Prometheus]
        end
    end
    
    U --> I --> LB1 --> WP
    U --> T --> WP
    I --> LB2 --> GP
    WP --> OP
    OP -.->|metrics| PP --> GP
```

## ğŸ“‹ Current Status

âœ… **Phase 1 Complete**: Infrastructure as Code deployed  
âœ… **Phase 2 Complete**: Enterprise repository structure  
âœ… **Phase 3 Complete**: Architecture diagrams & documentation  

## ğŸ“– Documentation

- **[Installation Guide](docs/deployment/installation.md)** - Complete setup instructions
- **[Architecture Overview](docs/architecture/overview.md)** - System design and components
- **[Operations Manual](docs/operations/)** - Day-2 operations and maintenance
- **[Development Guide](docs/development/)** - Contributing and development setup

## ğŸ› ï¸ Available Models

Your deployment includes these AI models:
- **CodeLlama** - AI model capabilities
- **Llama3.2:3b** - AI model capabilities
- **Gemma2:4b** - AI model capabilities

## ğŸ”§ Management Commands

```bash
# Check system status
./scripts/system-status.sh

# Add new AI models
./scripts/add-ollama-model-script.sh

# Download coding models
./scripts/download-coding-models.sh

# View deployment status
kubectl get pods -n ollama-stack
kubectl get services -n ollama-stack
```

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for:
- Development setup
- Code standards
- Testing procedures
- Release process

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

## ğŸ†˜ Support

- ğŸ“– **Documentation**: Check the `docs/` directory
- ğŸ› **Issues**: [GitHub Issues](https://github.com/your-org/ollama-kubernetes-stack/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/your-org/ollama-kubernetes-stack/discussions)

---

**Generated on**: 2025-07-26  
**Powered by**: Kubernetes â€¢ Helm â€¢ Ollama â€¢ OpenWebUI â€¢ Grafana â€¢ Tailscale
